{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyP417fSlelaLhhAaWgYUdC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritwikraha/GenerativeFill-with-Keras-and-Diffusers/blob/main/imagediting_through_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Editing Through Text\n",
        "\n",
        "Using Keras CV, HuggingFace Diffusers, and Transformers to create a pipeline for editing images based on *just* the text prompt supplied.\n",
        "\n"
      ],
      "metadata": {
        "id": "SyNPv0MZUEoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and Imports"
      ],
      "metadata": {
        "id": "de3H5kFKSlQG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GRcCrjXP7eS"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -qq keras-cv tensorflow\n",
        "!pip install --upgrade -qq keras\n",
        "\n",
        "!pip install --upgrade -qq diffusers accelerate transformers\n",
        "\n",
        "!pip install --upgrade -qq git+https://github.com/IDEA-Research/GroundingDINO.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
        "!wget -q https://raw.githubusercontent.com/IDEA-Research/GroundingDINO/v0.1.0-alpha2/groundingdino/config/GroundingDINO_SwinT_OGC.py"
      ],
      "metadata": {
        "id": "BH6XkUMqQIfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import keras\n",
        "from keras import ops\n",
        "import keras_cv\n",
        "\n",
        "\n",
        "from diffusers import AutoPipelineForInpainting\n",
        "from groundingdino.util.inference import Model as GroundingDINO\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "T8kEtPmGQLVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GDINO_CONFIG_PATH = \"GroundingDINO_SwinT_OGC.py\"\n",
        "GDINO_WEIGHTS_PATH = \"groundingdino_swint_ogc.pth\"\n",
        "SAM_MODEL_NAME = \"sam_huge_sa1b\"\n",
        "\n",
        "IMAGE_SIZE = (1024, 1024)"
      ],
      "metadata": {
        "id": "Nh_cmheBQWJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the Image"
      ],
      "metadata": {
        "id": "On7ElFN1SurT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://storage.googleapis.com/keras-cv/test-images/mountain-dog.jpeg\"\n",
        "filepath = keras.utils.get_file(origin=image_url)\n",
        "image = np.array(keras.utils.load_img(filepath))\n",
        "image = ops.convert_to_numpy(ops.image.resize(image[None, ...], IMAGE_SIZE)[0])\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image / 255.0)\n",
        "plt.axis(\"on\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1hV_WIfQchn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the Text  "
      ],
      "metadata": {
        "id": "eyslBAK0S8wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\").to(device)"
      ],
      "metadata": {
        "id": "cysay2lyQdsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title What do you want to do? { run: \"auto\", form-width: \"100px\" }\n",
        "input_prompt = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Vwc_DqnGRbau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Find the objects that are swapped\"},\n",
        "    {\"role\": \"user\", \"content\": \"Swap mountain and lion\"},  # example 1\n",
        "    {\"role\": \"assistant\", \"content\": \"mountain, lion\"},  # example 1\n",
        "    {\"role\": \"user\", \"content\": \"Change the dog with cat\"},  # example 2\n",
        "    {\"role\": \"assistant\", \"content\": \"dog, cat\"},  # example 2\n",
        "    {\"role\": \"user\", \"content\": input_prompt}\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "generated_ids = model.generate(input_ids.to(device), max_new_tokens=1000, do_sample=True)\n",
        "outputs = tokenizer.batch_decode(generated_ids)"
      ],
      "metadata": {
        "id": "BHSocJYGQtjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = outputs[0].split(\"[/INST]\")[-1].split(\"</s>\")[0].split(\",\")\n",
        "target_object = data[0].strip()  # Remove leading/trailing spaces\n",
        "replacement = data[1].strip()\n",
        "\n",
        "print(f\"object: {target_object}\")\n",
        "print(f\"replacement: {replacement}\")"
      ],
      "metadata": {
        "id": "ZSj8iY8dR2kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "iwvIimlkTOsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_mask(mask, ax):\n",
        "    color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "\n",
        "def show_box(box, ax):\n",
        "    box = box.reshape(-1)\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(\n",
        "        plt.Rectangle((x0, y0), w, h, edgecolor=\"green\", facecolor=(0, 0, 0, 0), lw=2)\n",
        "    )"
      ],
      "metadata": {
        "id": "Yy3BoyEcSF8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the Model"
      ],
      "metadata": {
        "id": "CYaoB5eKTR4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sam_model = keras_cv.models.SegmentAnythingModel.from_preset(SAM_MODEL_NAME)\n",
        "grounding_dino = GroundingDINO(GDINO_CONFIG_PATH, GDINO_WEIGHTS_PATH)"
      ],
      "metadata": {
        "id": "93f677vsSRRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segmentation based on Text Input"
      ],
      "metadata": {
        "id": "lAqbzF1zTbtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_name = target_object\n",
        "\n",
        "# Grounding DINO\n",
        "boxes = grounding_dino.predict_with_caption(\n",
        "    image.astype(np.uint8),\n",
        "    object_name,\n",
        ")\n",
        "boxes = np.array(boxes[0].xyxy)\n",
        "\n",
        "# SAM\n",
        "outputs = sam_model.predict(\n",
        "    {\n",
        "        \"images\": np.repeat(image[np.newaxis, ...], boxes.shape[0], axis=0),\n",
        "        \"boxes\": boxes.reshape(-1, 1, 2, 2),\n",
        "    },\n",
        "    batch_size=1,\n",
        ")"
      ],
      "metadata": {
        "id": "VcUUwTMSSUCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show the Segmentation"
      ],
      "metadata": {
        "id": "aL_5FMH7Tkl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(image / 255.0)\n",
        "\n",
        "for mask in outputs[\"masks\"]:\n",
        "    mask = ops.image.resize(mask[0][..., None], IMAGE_SIZE)[..., 0]\n",
        "    mask = ops.convert_to_numpy(mask) > 0.0\n",
        "    show_mask(mask, plt.gca())\n",
        "    show_box(boxes, plt.gca())\n",
        "\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F_UVuk0HSWbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Editing using Inpainting"
      ],
      "metadata": {
        "id": "OBD4QaTxTrDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = AutoPipelineForInpainting.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ")\n",
        "pipeline.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "Uf687lBKSZds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Prompt based on Text Input"
      ],
      "metadata": {
        "id": "x0FkszTLTzpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"A {replacement} highly detailed, 8K\"\n",
        "output = pipeline(\n",
        "    prompt=prompt,\n",
        "    image=Image.fromarray(image.astype(np.uint8)),\n",
        "    mask_image=Image.fromarray(mask),\n",
        "    strength=0.6\n",
        ").images[0]"
      ],
      "metadata": {
        "id": "KsaigLdGScQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ta-Daa!"
      ],
      "metadata": {
        "id": "OUmFrXmLT_Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(output)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kdSXZmrxSdug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}